{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPEC2006_Cleaner.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "S2AyJ9orALWX",
        "Qt7whaYvSlK-",
        "HnKIr7tPDPOu",
        "Jnljevvqw1Pj",
        "X_GBH8bBk5uo",
        "UhrIihzOzwV6",
        "aXjUtvbhkDyo",
        "5YIs9wUZwHtW",
        "tsVSYI_suNCi",
        "VqwEw8aIvXfc",
        "DTneu-hmCnAm",
        "37CwhD7tIsC9",
        "esPcjPIfxfkr",
        "Nkyc8bT7gFBh",
        "Q0sEyRvCT3qf",
        "kb6CvWATAmN3",
        "Cq5nz88_df6w"
      ],
      "mount_file_id": "1ksl1_oTmE24k2KnDfJz4pnYCdoFQ4joH",
      "authorship_tag": "ABX9TyOQdtwvwFTRjHnM6pd3stj0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cengizmehmet/DesignPatterns/blob/main/SPEC2006/SPEC2006_Cleaner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREPROCESSING OF THE SPEC2006 DATASET**"
      ],
      "metadata": {
        "id": "iBHHRGNRM6ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepared by Mehmet CENGIZ**\n",
        "\n",
        "ORCID: 0000-0003-4972-167X\n",
        "\n",
        "As we use this format of the SPEC2006 dataset in our studies, we modify it based on our requirements. Those who will use this script is free to modify this based on their needs. Please do not forget to cite our studies."
      ],
      "metadata": {
        "id": "Yx86g1qwO1ss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "riNhaheHO8GT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script is prepared for making operable the SPEC2006 dataset to use in our further studies. Even though the dataset was prepared carefully by practitioners, there are many unnecessary and untidy data in it. We will explain every process applied on columns onwards."
      ],
      "metadata": {
        "id": "eo0tmJA1v6Jj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdW_TVIWbfKb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from typing import Tuple\n",
        "import enum"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Versions:**\n",
        "\n",
        "We developed this system using the versions:\n",
        "\n",
        "\n",
        "*   Python: 3.7.12\n",
        "*   Pandas: 1.1.5\n",
        "*   Regular expressions: 2.2.1\n",
        "\n"
      ],
      "metadata": {
        "id": "ccqw-7snw-oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC2WYXOKyd4e",
        "outputId": "0fd90870-e540-4005-cd67-50091666d74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.__version__)\n",
        "print(re.__version__)"
      ],
      "metadata": {
        "id": "KpWGKPenxQez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d6c9c9-d160-453a-a848-cd1f57d49dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1.5\n",
            "2.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "X1uCYGM5OFzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In our case, we access the dataset from our own Google Drive folder. Thus, in your study, you have to change the path where you access the dataset.**"
      ],
      "metadata": {
        "id": "P2uKfXBDA66B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Colab Notebooks/Datasets/SPEC/SPEC2006_Original.csv' # DO NOT FORGET TO CHANGE THE PATH"
      ],
      "metadata": {
        "id": "MgmBV_Rlr3Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "Oq7LsHm5sF0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "70A9nrADOIHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **THE DATASET BEFORE PREPROCESSING**"
      ],
      "metadata": {
        "id": "S2AyJ9orALWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After preprocessing, the dataset will be changed in many ways. In the section below, we present the original formats of some columns of the dataset."
      ],
      "metadata": {
        "id": "EsCAa0j9APyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Column names:**"
      ],
      "metadata": {
        "id": "pjZUHertoM8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset.columns))\n",
        "print(dataset.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3h3nAoG28Ho",
        "outputId": "f1c7f9c7-b892-434f-de66-573a81a08c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33\n",
            "Index(['Benchmark', 'Hardware Vendor\\t', 'System', 'Result', 'Baseline',\n",
            "       '# Cores', '# Chips ', '# Cores Per Chip ', '# Threads Per Core',\n",
            "       'Processor ', 'Processor MHz', 'Processor Characteristics',\n",
            "       'CPU(s) Orderable', 'Auto Parallelization', 'Base Pointer Size',\n",
            "       'Peak Pointer Size', '1st Level Cache', '2nd Level Cache',\n",
            "       '3rd Level Cache', 'Other Cache', 'Memory', 'Operating System',\n",
            "       'File System', 'Compiler', 'HW Avail', 'SW Avail', 'License',\n",
            "       'Tested By', 'Test Sponsor', 'Test Date', 'Published', 'Updated ',\n",
            "       'Disclosures'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data types:**"
      ],
      "metadata": {
        "id": "Ie4VVGHI7kM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU8GOby_7n0n",
        "outputId": "8b5385b2-eb5f-475b-9b8e-46ed60737fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Benchmark                     object\n",
              "Hardware Vendor\\t             object\n",
              "System                        object\n",
              "Result                       float64\n",
              "Baseline                     float64\n",
              "# Cores                        int64\n",
              "# Chips                        int64\n",
              "# Cores Per Chip               int64\n",
              "# Threads Per Core             int64\n",
              "Processor                     object\n",
              "Processor MHz                  int64\n",
              "Processor Characteristics     object\n",
              "CPU(s) Orderable              object\n",
              "Auto Parallelization          object\n",
              "Base Pointer Size             object\n",
              "Peak Pointer Size             object\n",
              "1st Level Cache               object\n",
              "2nd Level Cache               object\n",
              "3rd Level Cache               object\n",
              "Other Cache                   object\n",
              "Memory                        object\n",
              "Operating System              object\n",
              "File System                   object\n",
              "Compiler                      object\n",
              "HW Avail                      object\n",
              "SW Avail                      object\n",
              "License                        int64\n",
              "Tested By                     object\n",
              "Test Sponsor                  object\n",
              "Test Date                     object\n",
              "Published                     object\n",
              "Updated                       object\n",
              "Disclosures                   object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shape:**"
      ],
      "metadata": {
        "id": "7rPsSDlQ7uLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Rl1nXzv7wNZ",
        "outputId": "f1514618-4e48-4ef1-9e39-abe95386d2e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48381, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The dataset itself:**"
      ],
      "metadata": {
        "id": "WhkkvpKMoP0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab's dataset formatter is not working well, because of so many columns and rows. The limit is 20 columns and 20000 rows. Those who want to see the dataset tidier and interactive may click the baton symbol left down corner."
      ],
      "metadata": {
        "id": "KSZB0lKZN5Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rgZRXdQNefp",
        "outputId": "38804c9b-e25c-45f6-d745-71f82f3b0236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2bc5797e-04fd-4baf-b1a7-ee6d854b4641\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Benchmark</th>\n",
              "      <th>Hardware Vendor\\t</th>\n",
              "      <th>System</th>\n",
              "      <th>Result</th>\n",
              "      <th>Baseline</th>\n",
              "      <th># Cores</th>\n",
              "      <th># Chips</th>\n",
              "      <th># Cores Per Chip</th>\n",
              "      <th># Threads Per Core</th>\n",
              "      <th>Processor</th>\n",
              "      <th>Processor MHz</th>\n",
              "      <th>Processor Characteristics</th>\n",
              "      <th>CPU(s) Orderable</th>\n",
              "      <th>Auto Parallelization</th>\n",
              "      <th>Base Pointer Size</th>\n",
              "      <th>Peak Pointer Size</th>\n",
              "      <th>1st Level Cache</th>\n",
              "      <th>2nd Level Cache</th>\n",
              "      <th>3rd Level Cache</th>\n",
              "      <th>Other Cache</th>\n",
              "      <th>Memory</th>\n",
              "      <th>Operating System</th>\n",
              "      <th>File System</th>\n",
              "      <th>Compiler</th>\n",
              "      <th>HW Avail</th>\n",
              "      <th>SW Avail</th>\n",
              "      <th>License</th>\n",
              "      <th>Tested By</th>\n",
              "      <th>Test Sponsor</th>\n",
              "      <th>Test Date</th>\n",
              "      <th>Published</th>\n",
              "      <th>Updated</th>\n",
              "      <th>Disclosures</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CINT2006</td>\n",
              "      <td>ACTION S.A.</td>\n",
              "      <td>ACTINA SOLAR 110 S6 (Intel Xeon E3-1220 v3, 3....</td>\n",
              "      <td>58.7</td>\n",
              "      <td>56.9</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Intel Xeon E3-1220 v3</td>\n",
              "      <td>3100</td>\n",
              "      <td>Intel Turbo Boost Technology up to 3.50 GHz</td>\n",
              "      <td>1 chip</td>\n",
              "      <td>Yes</td>\n",
              "      <td>32/64-bit</td>\n",
              "      <td>32/64-bit</td>\n",
              "      <td>32 KB I + 32 KB D on chip per core</td>\n",
              "      <td>256 KB I+D on chip per core</td>\n",
              "      <td>8 MB I+D on chip per chip</td>\n",
              "      <td>None</td>\n",
              "      <td>32 GB (4 x 8 GB 2Rx8 PC3-12800E-11, ECC)</td>\n",
              "      <td>Red Hat Enterprise Linux Server release 7.1, (...</td>\n",
              "      <td>ext4</td>\n",
              "      <td>C/C++: Version 16.0.0.047 of Intel C++ Studio ...</td>\n",
              "      <td>Sep-2014</td>\n",
              "      <td>Aug-2015</td>\n",
              "      <td>9008</td>\n",
              "      <td>ACTION S.A.</td>\n",
              "      <td>ACTION S.A.</td>\n",
              "      <td>Dec-2015</td>\n",
              "      <td>Dec-2015</td>\n",
              "      <td>Dec-2015</td>\n",
              "      <td>&lt;A HREF=\"/cpu2006/results/res2015q4/cpu2006-20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CINT2006</td>\n",
              "      <td>ACTION S.A.</td>\n",
              "      <td>ACTINA SOLAR 202 S6 (Intel Xeon E5-2697 v3, 2....</td>\n",
              "      <td>67.5</td>\n",
              "      <td>64.4</td>\n",
              "      <td>28</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>Intel Xeon E5-2697 v3</td>\n",
              "      <td>2600</td>\n",
              "      <td>Intel Turbo Boost Technology up to 3.60 GHz</td>\n",
              "      <td>1,2 chips</td>\n",
              "      <td>Yes</td>\n",
              "      <td>32/64-bit</td>\n",
              "      <td>32/64-bit</td>\n",
              "      <td>32 KB I + 32 KB D on chip per core</td>\n",
              "      <td>256 KB I+D on chip per core</td>\n",
              "      <td>35 MB I+D on chip per chip</td>\n",
              "      <td>None</td>\n",
              "      <td>256 GB (16 x 16 GB 2Rx4 PC4-2400P-R, running a...</td>\n",
              "      <td>Red Hat Enterprise Linux Server release 7.1, (...</td>\n",
              "      <td>ext4</td>\n",
              "      <td>C/C++: Version 16.0.0.047 of Intel C++ Studio ...</td>\n",
              "      <td>Sep-2014</td>\n",
              "      <td>Aug-2015</td>\n",
              "      <td>9008</td>\n",
              "      <td>ACTION S.A.</td>\n",
              "      <td>ACTION S.A.</td>\n",
              "      <td>Nov-2015</td>\n",
              "      <td>Dec-2015</td>\n",
              "      <td>Dec-2015</td>\n",
              "      <td>&lt;A HREF=\"/cpu2006/results/res2015q4/cpu2006-20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CINT2006</td>\n",
              "      <td>ACTION S.A.</td>\n",
              "      <td>ACTINA SOLAR 205 S5 (Intel Xeon E5-2420)</td>\n",
              "      <td>35.8</td>\n",
              "      <td>32.8</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>Intel Xeon E5-2420</td>\n",
              "      <td>1900</td>\n",
              "      <td>Intel Turbo Boost Technology up to 2.40 GHz</td>\n",
              "      <td>1,2 chips</td>\n",
              "      <td>Yes</td>\n",
              "      <td>32-bit</td>\n",
              "      <td>32/64-bit</td>\n",
              "      <td>32 KB I + 32 KB D on chip per core</td>\n",
              "      <td>256 KB I+D on chip per core</td>\n",
              "      <td>15 MB I+D on chip per chip</td>\n",
              "      <td>None</td>\n",
              "      <td>96 GB (6 x 16 GB 2Rx4 PC3-12800R-11, ECC, runn...</td>\n",
              "      <td>SUSE Linux Enterprise Server 11 SP2 (x86_64), ...</td>\n",
              "      <td>ext3</td>\n",
              "      <td>C/C++: Version 12.1.0.225 of Intel C++ Studio ...</td>\n",
              "      <td>May-2012</td>\n",
              "      <td>Feb-2012</td>\n",
              "      <td>9008</td>\n",
              "      <td>ACTION S.A.</td>\n",
              "      <td>ACTION S.A.</td>\n",
              "      <td>Oct-2012</td>\n",
              "      <td>Dec-2012</td>\n",
              "      <td>Jul-2014</td>\n",
              "      <td>&lt;A HREF=\"/cpu2006/results/res2012q4/cpu2006-20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CINT2006</td>\n",
              "      <td>ACTION S.A.</td>\n",
              "      <td>ACTINA SOLAR 210 X5 (Intel Xeon E5-2630)</td>\n",
              "      <td>41.5</td>\n",
              "      <td>38.9</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>Intel Xeon E5-2630</td>\n",
              "      <td>2300</td>\n",
              "      <td>Intel Turbo Boost Technology up to 2.80 GHz</td>\n",
              "      <td>1,2 chips</td>\n",
              "      <td>Yes</td>\n",
              "      <td>32-bit</td>\n",
              "      <td>32/64-bit</td>\n",
              "      <td>32 KB I + 32 KB D on chip per core</td>\n",
              "      <td>256 KB I+D on chip per core</td>\n",
              "      <td>15 MB I+D on chip per chip</td>\n",
              "      <td>None</td>\n",
              "      <td>128 GB (16 x 8 GB 2Rx4 PC3-12800R-11, ECC)</td>\n",
              "      <td>SUSE Linux Enterprise Server 11 SP2 (x86_64), ...</td>\n",
              "      <td>ext3</td>\n",
              "      <td>C/C++: Version 12.1.0.225 of Intel C++ Studio ...</td>\n",
              "      <td>Mar-2012</td>\n",
              "      <td>Feb-2012</td>\n",
              "      <td>9008</td>\n",
              "      <td>ACTION S.A.</td>\n",
              "      <td>ACTION S.A.</td>\n",
              "      <td>Oct-2012</td>\n",
              "      <td>Dec-2012</td>\n",
              "      <td>Jul-2014</td>\n",
              "      <td>&lt;A HREF=\"/cpu2006/results/res2012q4/cpu2006-20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CINT2006</td>\n",
              "      <td>ACTION S.A.</td>\n",
              "      <td>ACTINA SOLAR 210 X6 (Intel Xeon E5-2603 v4, 1....</td>\n",
              "      <td>35.4</td>\n",
              "      <td>34.4</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>Intel Xeon E5-2603 v4</td>\n",
              "      <td>1700</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1,2 chips</td>\n",
              "      <td>Yes</td>\n",
              "      <td>32/64-bit</td>\n",
              "      <td>32/64-bit</td>\n",
              "      <td>32 KB I + 32 KB D on chip per core</td>\n",
              "      <td>256 KB I+D on chip per core</td>\n",
              "      <td>15 MB I+D on chip per chip</td>\n",
              "      <td>None</td>\n",
              "      <td>256 GB (16 x 16 GB 2Rx4 PC4-2133P-R, running a...</td>\n",
              "      <td>Red Hat Enterprise Linux Server release 7.2, (...</td>\n",
              "      <td>ext4</td>\n",
              "      <td>C/C++: Version 16.0.3.210 of Intel C++ Studio ...</td>\n",
              "      <td>Mar-2016</td>\n",
              "      <td>Mar-2016</td>\n",
              "      <td>9008</td>\n",
              "      <td>ACTION S.A.</td>\n",
              "      <td>ACTION S.A.</td>\n",
              "      <td>Sep-2016</td>\n",
              "      <td>Nov-2016</td>\n",
              "      <td>Nov-2016</td>\n",
              "      <td>&lt;A HREF=\"/cpu2006/results/res2016q4/cpu2006-20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48376</th>\n",
              "      <td>CFP2006rate</td>\n",
              "      <td>Wipro Limited</td>\n",
              "      <td>Wipro NetPowerZ2243/NetPowerZ2243R</td>\n",
              "      <td>258.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>Intel Xeon X5670</td>\n",
              "      <td>2933</td>\n",
              "      <td>Intel Turbo Boost Technology up to 3.33 GHz</td>\n",
              "      <td>1,2 chips</td>\n",
              "      <td>No</td>\n",
              "      <td>64-bit</td>\n",
              "      <td>32/64-bit</td>\n",
              "      <td>32 KB I + 32 KB D on chip per core</td>\n",
              "      <td>256 KB I+D on chip per core</td>\n",
              "      <td>12 MB I+D on chip per chip</td>\n",
              "      <td>None</td>\n",
              "      <td>96 GB (12 x 8 GB 2Rx4 PC3-10600R-9, ECC)</td>\n",
              "      <td>SuSe Linux SLES10 (x86_64) SP1, Kernel, 2.6.27...</td>\n",
              "      <td>ReiserFS</td>\n",
              "      <td>Intel C++ and Fortran Intel 64 Compiler XE, fo...</td>\n",
              "      <td>Apr-2011</td>\n",
              "      <td>May-2011</td>\n",
              "      <td>937</td>\n",
              "      <td>Wipro Limited</td>\n",
              "      <td>Wipro Limited</td>\n",
              "      <td>Jun-2011</td>\n",
              "      <td>Aug-2011</td>\n",
              "      <td>Jul-2014</td>\n",
              "      <td>&lt;A HREF=\"/cpu2006/results/res2011q3/cpu2006-20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48377</th>\n",
              "      <td>CFP2006rate</td>\n",
              "      <td>YOYOtech</td>\n",
              "      <td>Fi7EPOWER MLK1610 (Intel Core i7-965)</td>\n",
              "      <td>88.3</td>\n",
              "      <td>84.7</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>Intel Core i7-965 Extreme Edition</td>\n",
              "      <td>3733</td>\n",
              "      <td>Intel Turbo Boost Technology disabled, clocked...</td>\n",
              "      <td>1 chip</td>\n",
              "      <td>No</td>\n",
              "      <td>32-bit</td>\n",
              "      <td>32-bit</td>\n",
              "      <td>32 KB I + 32 KB D on chip per core</td>\n",
              "      <td>256 KB I+D on chip per core</td>\n",
              "      <td>8 MB I+D on chip per chip</td>\n",
              "      <td>None</td>\n",
              "      <td>9 GB (3x 2GB and 3x 1GB Corsair DDR3-1066, 9-9...</td>\n",
              "      <td>Windows Vista Ultimate w/ SP1 (64-bit)</td>\n",
              "      <td>NTFS</td>\n",
              "      <td>Intel C++ Compiler Professional 11.0 for IA32,...</td>\n",
              "      <td>Nov-2008</td>\n",
              "      <td>Nov-2008</td>\n",
              "      <td>3772</td>\n",
              "      <td>Future Publishing Ltd.</td>\n",
              "      <td>Future Publishing Ltd.</td>\n",
              "      <td>Oct-2008</td>\n",
              "      <td>Jan-2009</td>\n",
              "      <td>Jul-2014</td>\n",
              "      <td>&lt;A HREF=\"/cpu2006/results/res2009q1/cpu2006-20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48378</th>\n",
              "      <td>CFP2006rate</td>\n",
              "      <td>Yadro</td>\n",
              "      <td>Yadro Vesnin (2.92 GHz, 40 cores, RHEL 7.4)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>IBM POWER8</td>\n",
              "      <td>2926</td>\n",
              "      <td>Intelligent Energy Optimization enabled, up to...</td>\n",
              "      <td>1-4 chips</td>\n",
              "      <td>No</td>\n",
              "      <td>64-bit</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>32 KB I + 64 KB D on chip per core</td>\n",
              "      <td>512 KB I+D on chip per core</td>\n",
              "      <td>8 MB I+D on chip per core</td>\n",
              "      <td>16 MB I+D off chip per 8 DIMMs</td>\n",
              "      <td>4 TB (128 x 32 GB 2Rx4 PC4 - 2400T, running at...</td>\n",
              "      <td>Red Hat Enterprise Linux Server release 7.4, (...</td>\n",
              "      <td>xfs</td>\n",
              "      <td>C/C++: Version 13.1.5 of IBM XL C/C++ for Linu...</td>\n",
              "      <td>Dec-2017</td>\n",
              "      <td>Dec-2016</td>\n",
              "      <td>4813</td>\n",
              "      <td>Yadro</td>\n",
              "      <td>Yadro</td>\n",
              "      <td>Dec-2017</td>\n",
              "      <td>Mar-2018</td>\n",
              "      <td>Mar-2018</td>\n",
              "      <td>&lt;A HREF=\"/cpu2006/results/res2018q1/cpu2006-20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48379</th>\n",
              "      <td>CFP2006rate</td>\n",
              "      <td>Yadro</td>\n",
              "      <td>Yadro Vesnin (3.32 GHz, 32 cores, RHEL 7.2)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1380.0</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>IBM POWER8</td>\n",
              "      <td>3325</td>\n",
              "      <td>Intelligent Energy Optimization enabled, up to...</td>\n",
              "      <td>1-4 chips</td>\n",
              "      <td>No</td>\n",
              "      <td>64-bit</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>32 KB I + 64 KB D on chip per core</td>\n",
              "      <td>512 KB I+D on chip per core</td>\n",
              "      <td>8 MB I+D on chip per core</td>\n",
              "      <td>16 MB I+D off chip per 8 DIMMs</td>\n",
              "      <td>8 TB (128 x 64 GB 4Rx4 PC4 - 2400T, running at...</td>\n",
              "      <td>Red Hat Enterprise Linux Server release 7.2, (...</td>\n",
              "      <td>xfs</td>\n",
              "      <td>C/C++: Version 13.1.5 of IBM XL C/C++ for Linu...</td>\n",
              "      <td>Dec-2017</td>\n",
              "      <td>Dec-2016</td>\n",
              "      <td>4813</td>\n",
              "      <td>Yadro</td>\n",
              "      <td>Yadro</td>\n",
              "      <td>Dec-2017</td>\n",
              "      <td>Mar-2018</td>\n",
              "      <td>Mar-2018</td>\n",
              "      <td>&lt;A HREF=\"/cpu2006/results/res2018q1/cpu2006-20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48380</th>\n",
              "      <td>CFP2006rate</td>\n",
              "      <td>ZTE</td>\n",
              "      <td>ATCA SBCR (Intel Xeon E5-2628L v2)</td>\n",
              "      <td>406.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>Intel Xeon E5-2628L v2</td>\n",
              "      <td>1900</td>\n",
              "      <td>Intel Turbo Boost Technology up to 2.40 GHz</td>\n",
              "      <td>1,2 chip</td>\n",
              "      <td>No</td>\n",
              "      <td>32/64-bit</td>\n",
              "      <td>32/64-bit</td>\n",
              "      <td>32 KB I + 32 KB D on chip per core</td>\n",
              "      <td>256 KB I+D on chip per core</td>\n",
              "      <td>20 MB I+D on chip per chip</td>\n",
              "      <td>None</td>\n",
              "      <td>128 GB (8 x 16 GB 2Rx4 PC3-10600R-9 ECC)</td>\n",
              "      <td>Red Hat Enterprise Linux Server release, 7.0(M...</td>\n",
              "      <td>xfs</td>\n",
              "      <td>C/C++: Version 15.0.0.090 of Intel C++ Studio ...</td>\n",
              "      <td>Sep-2013</td>\n",
              "      <td>Sep-2014</td>\n",
              "      <td>3834</td>\n",
              "      <td>ZTE</td>\n",
              "      <td>ZTE</td>\n",
              "      <td>Aug-2015</td>\n",
              "      <td>Sep-2015</td>\n",
              "      <td>Sep-2015</td>\n",
              "      <td>&lt;A HREF=\"/cpu2006/results/res2015q3/cpu2006-20...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48381 rows × 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bc5797e-04fd-4baf-b1a7-ee6d854b4641')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2bc5797e-04fd-4baf-b1a7-ee6d854b4641 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2bc5797e-04fd-4baf-b1a7-ee6d854b4641');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Benchmark  ...                                        Disclosures\n",
              "0         CINT2006  ...  <A HREF=\"/cpu2006/results/res2015q4/cpu2006-20...\n",
              "1         CINT2006  ...  <A HREF=\"/cpu2006/results/res2015q4/cpu2006-20...\n",
              "2         CINT2006  ...  <A HREF=\"/cpu2006/results/res2012q4/cpu2006-20...\n",
              "3         CINT2006  ...  <A HREF=\"/cpu2006/results/res2012q4/cpu2006-20...\n",
              "4         CINT2006  ...  <A HREF=\"/cpu2006/results/res2016q4/cpu2006-20...\n",
              "...            ...  ...                                                ...\n",
              "48376  CFP2006rate  ...  <A HREF=\"/cpu2006/results/res2011q3/cpu2006-20...\n",
              "48377  CFP2006rate  ...  <A HREF=\"/cpu2006/results/res2009q1/cpu2006-20...\n",
              "48378  CFP2006rate  ...  <A HREF=\"/cpu2006/results/res2018q1/cpu2006-20...\n",
              "48379  CFP2006rate  ...  <A HREF=\"/cpu2006/results/res2018q1/cpu2006-20...\n",
              "48380  CFP2006rate  ...  <A HREF=\"/cpu2006/results/res2015q3/cpu2006-20...\n",
              "\n",
              "[48381 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Common Functions"
      ],
      "metadata": {
        "id": "Qt7whaYvSlK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some functions below require a column name as the parameter. In order to prevent errors from passing in invalid constants, we defined an enumeration class."
      ],
      "metadata": {
        "id": "XLGGNbzrrlRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Column_Names(enum.Enum):\n",
        "   system = \"System\"\n",
        "   file_system = \"File_System\"\n",
        "   first_cache = \"1st_Level_Cache\"\n",
        "   second_cache = \"2nd_Level_Cache\"\n",
        "   third_cache = \"3rd_Level_Cache\"\n",
        "   other_cache = \"Other_Cache\"\n",
        "   result = \"Result\""
      ],
      "metadata": {
        "id": "_TXFKdwDDhli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method Name:** drop_empties\n",
        "\n",
        "**Parameters:** pd.DataFrame, Column_Names, str\n",
        "\n",
        "**Return:** pd.DataFrame\n",
        "\n",
        "This function deletes the rows containing the character entered according to the specified column. e.g. delete rows with value of 0 in the Result column."
      ],
      "metadata": {
        "id": "S97tUcfcsqIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_empties(dataset: pd.DataFrame, column_name: Column_Names, empty_character: str) -> pd.DataFrame:\n",
        "  dataset.drop(dataset.index[dataset[column_name.value] == empty_character], inplace = True)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "TQ3wcC3GDa6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method Name:** remove_between_with_delimiter\n",
        "\n",
        "**Parameters:** pd.DataFrame, str, str\n",
        "\n",
        "**Return:** pd.DataFrame\n",
        "\n",
        "This function removes all characters between two delimiters including delimiters from a string. e. g.\n",
        "> input: Test system (test info)\n",
        "\n",
        "> delimiters: \"(\" and \")\"\n",
        "\n",
        "> output: Test system"
      ],
      "metadata": {
        "id": "sZhr2MzU8a6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_between_with_delimiter(column: pd.DataFrame.columns, delimiter1: str, delimiter2: str) -> pd.DataFrame.columns:\n",
        "  column = list(column)\n",
        "  delimiter1 = \"\\\\\" + delimiter1\n",
        "  delimiter2 = \"\\\\\" + delimiter2\n",
        "  pattern = pattern = delimiter1 + \".*?\" + delimiter2\n",
        "  count = 0\n",
        "  while count < len(column):\n",
        "    column[count] = re.sub(pattern, \"\", column[count])\n",
        "    count += 1\n",
        "  column = [s.strip() for s in column]\n",
        "  return column"
      ],
      "metadata": {
        "id": "py9NtTy2ja6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method Name:** remove_after_with_delimiter\n",
        "\n",
        "**Parameters:** pd.DataFrame, str, \n",
        "\n",
        "**Return:** pd.DataFrame\n",
        "\n",
        "This function removes all characters after a delimiter including the delimiter from a string. e. g.\n",
        "> input: Test system - test info\n",
        "\n",
        "> delimiter: \"-\"\n",
        "\n",
        "> output: Test system"
      ],
      "metadata": {
        "id": "hZeaPAyh9eJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_after_with_delimiter(column: pd.DataFrame.columns, delimiter: str) -> pd.DataFrame.columns:\n",
        "  column = list(column)\n",
        "  count = 0\n",
        "  while count < len(column):\n",
        "    column[count] = column[count].split(delimiter, 1)[0]\n",
        "    count += 1\n",
        "  column = [s.strip() for s in column]\n",
        "  return column"
      ],
      "metadata": {
        "id": "Kzck6BymN2TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method Name:** eliminate_non_digits\n",
        "\n",
        "**Parameters:** str\n",
        "\n",
        "**Return:** int\n",
        "\n",
        "This function removes all non-digit characters from a string and returns an integer. e. g.\n",
        "> input: 45 kb info\n",
        "\n",
        "> output: 45"
      ],
      "metadata": {
        "id": "ij7RtsyW9-uO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eliminate_non_digits(text: str) -> int:\n",
        "  numeric_filter = filter(str.isdigit, text)\n",
        "  digits = \"\".join(numeric_filter)\n",
        "  if digits == \"\":\n",
        "    return 0\n",
        "  else:\n",
        "    return int(digits)"
      ],
      "metadata": {
        "id": "xaPAoifkXErZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method Name:** find_anagrams\n",
        "\n",
        "**Parameters:** pd.DataFrame.columns\n",
        "\n",
        "**Return:** Tuple[list, list]\n",
        "\n",
        "This function was designed to find the whole combinations of a string. The main goal is to find duplicates in columns such as \"Pentium dual core e2140\" and \"Pentium dualcore e2140\". The main approach is to find anagrams."
      ],
      "metadata": {
        "id": "4ocRiyDE-h3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_anagrams(column: pd.DataFrame.columns) -> Tuple[list, list]:\n",
        "  values = list(set(column))\n",
        "  checked = [False for i in range(len(values))]\n",
        "  originals = []\n",
        "  anagrams = []\n",
        "  i = 0\n",
        "  while i < len(values):\n",
        "    if checked[i] == False:\n",
        "      checked[i] = True\n",
        "      str1 = sorted((values[i].replace(\"-\", \"\")).replace(\" \",\"\"))\n",
        "      j = i + 1\n",
        "      while j < len(values):\n",
        "        if checked[j] == False:\n",
        "          str2 = sorted((values[j].replace(\"-\", \"\")).replace(\" \",\"\"))\n",
        "          if str1 == str2:\n",
        "            checked[j] = True\n",
        "            originals.append(values[i])\n",
        "            anagrams.append(values[j])\n",
        "            values[j] == values[i]          \n",
        "        j += 1\n",
        "    i += 1\n",
        "  return originals, anagrams"
      ],
      "metadata": {
        "id": "xYs---dgs89x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PRE CLEARING**"
      ],
      "metadata": {
        "id": "HnKIr7tPDPOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clearing column names**"
      ],
      "metadata": {
        "id": "ncqd65GoDeRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Column names have white spaces between words. In order to reach them easily in the script, we add \"_\" between words and trim each other. By doing this, a naming convention was created."
      ],
      "metadata": {
        "id": "h0wNaHLPHzVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_column_names(dataset):\n",
        "  column_names = dataset.columns\n",
        "  column_names = [s.strip() for s in column_names]\n",
        "  column_names = [s.replace(' ', '_') for s in column_names]\n",
        "  dataset.columns = column_names\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "RMtel_M60Jke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = clean_column_names(dataset)"
      ],
      "metadata": {
        "id": "CIC1D8LZgPY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIXhYQj_2YS2",
        "outputId": "7ebf8591-7b85-4487-f951-cf3a320ede46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Benchmark', 'Hardware_Vendor', 'System', 'Result', 'Baseline',\n",
              "       '#_Cores', '#_Chips', '#_Cores_Per_Chip', '#_Threads_Per_Core',\n",
              "       'Processor', 'Processor_MHz', 'Processor_Characteristics',\n",
              "       'CPU(s)_Orderable', 'Auto_Parallelization', 'Base_Pointer_Size',\n",
              "       'Peak_Pointer_Size', '1st_Level_Cache', '2nd_Level_Cache',\n",
              "       '3rd_Level_Cache', 'Other_Cache', 'Memory', 'Operating_System',\n",
              "       'File_System', 'Compiler', 'HW_Avail', 'SW_Avail', 'License',\n",
              "       'Tested_By', 'Test_Sponsor', 'Test_Date', 'Published', 'Updated',\n",
              "       'Disclosures'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VVsheKCoDiM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clearing rows**"
      ],
      "metadata": {
        "id": "pSx1S6bT7U0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains some inconclusive tests. Result values were entered as 0 in these tests by the practitioners. First, we started by eliminating these lines."
      ],
      "metadata": {
        "id": "QCfP56E27giG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "empty_char = 0\n",
        "dataset = drop_empties(dataset, Column_Names.result, empty_char)"
      ],
      "metadata": {
        "id": "WeV6Pwhi5XMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5lZxuehZDkMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **COLUMNS TO USE AS IS**"
      ],
      "metadata": {
        "id": "Jnljevvqw1Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some columns can be used as they are because their contents are quite clear. The columns are:\n",
        "\n",
        "*   Processor MHz\n",
        "*   Operating System\n",
        "*   Auto Parallelization\n",
        "*   Base Pointer Size\n",
        "*   Peak Pointer Size\n",
        "*   Compiler\n",
        "*   HW Avail\n",
        "*   SW Avail"
      ],
      "metadata": {
        "id": "xbexxWInw7Tr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The columns \"Result\" and \"Baseline\" are target attributes. Therefore we do not change them."
      ],
      "metadata": {
        "id": "jBF7NM-jyEXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **COLUMNS NOT CONSIDERED TO BE USED**"
      ],
      "metadata": {
        "id": "X_GBH8bBk5uo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The columns\n",
        "\n",
        "*   Benchmark\n",
        "*   Licence\n",
        "*   Tested By\n",
        "*   Test Sponsor\n",
        "*   Test Date\n",
        "*   Published\n",
        "*   Updated\n",
        "*   Disclosure\n",
        "\n",
        "are irrelevant for our further study. Therefore, we dropped them."
      ],
      "metadata": {
        "id": "f20Qp1KalEpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(['Benchmark'], axis = 1)\n",
        "dataset = dataset.drop(['License'], axis = 1)\n",
        "dataset = dataset.drop(['Tested_By'], axis = 1)\n",
        "dataset = dataset.drop(['Test_Sponsor'], axis = 1)\n",
        "dataset = dataset.drop(['Test_Date'], axis = 1)\n",
        "dataset = dataset.drop(['Published'], axis = 1)\n",
        "dataset = dataset.drop(['Updated'], axis = 1)\n",
        "dataset = dataset.drop(['Disclosures'], axis = 1)"
      ],
      "metadata": {
        "id": "svBZuUclHtCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **COLUMNS TO BE CORRECTED**"
      ],
      "metadata": {
        "id": "UhrIihzOzwV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **HARDWARE VENDOR**"
      ],
      "metadata": {
        "id": "aXjUtvbhkDyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Originally, there are 59 different hardware vendors. However, after we cleaned the rows containing 0 values, the number decreased to 53."
      ],
      "metadata": {
        "id": "wHxxSkH7uWWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Hardware_Vendor'] = dataset['Hardware_Vendor'].str.lower()\n",
        "dataset['Hardware_Vendor'] = dataset['Hardware_Vendor'].str.strip()\n",
        "vendors = set(list(dataset['Hardware_Vendor']))\n",
        "print(len(vendors))\n",
        "print(sorted(vendors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "087kAM24vQ1n",
        "outputId": "f13f1643-3581-4b61-b1f5-0e6a16f5d460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53\n",
            "['acer incorporated', 'action s.a.', 'apple computer, inc.', 'asus computer international', 'asustek computer inc.', 'boxx technologies, inc.', 'bull sas', 'cisco systems', 'clearcube technology', 'clevo', 'cryo performance computing ltd', 'dell inc.', 'e4 computer engineering s.p.a.', 'format', 'fujitsu', 'fujitsu limited', 'fujitsu siemens computers', 'giga-byte technology co. ltd.', 'gigabyte technology co., ltd.', 'h3c', 'hewlett packard enterprise', 'hewlett-packard company', 'hitachi', 'huawei', 'hypertechnologies ciara, inc', 'ibm corporation', 'incom s.a.', 'inspur corporation', 'intel corporation', 'itautec', 'iwill corporation', 'lenovo global technology', 'lenovo group limited', 'm computers s.r.o.', 'maxdata ag', 'microsoft corporation', 'msi', 'nec corporation', 'nokia', 'ntt system s. a.', 'oracle corporation', 'pc factory s.a.', 'quanta cloud technology', 'quanta computer inc.', 'sgi', 'sugon', 'sun microsystems', 'supermicro', 'tyan', 'unisys corporation', 'wipro limited', 'yoyotech', 'zte']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the column, there are duplicated vendors such as \"Hewlett-Packard\" and \"Hewlett Packard\". We need to make them one. It is a quite straightforward process, there is no smart approach. However, in order to not lose any vendor the coding order is important."
      ],
      "metadata": {
        "id": "x-sx1M-7vjOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"computer\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"corporation\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"technology\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \",\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"limited\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"computing\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"s.\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"global\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"group\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"company\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"enterprise\")"
      ],
      "metadata": {
        "id": "m_-UGWAhxLOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **Note:**\n",
        "The Dataframe.replace() method is applied to dataframes and series, and it works only in case when the whole item of that series or dataframe coincides with the indicated value to be replaced.\n",
        "\n",
        ">The method pandas.Series.str.replace() instead, is applied only to the series of strings, and in each item of that series, it looks for a pattern to be replaced. This pattern can coincide with the whole item, or with a part of it. This means the coinciding part will be replaced.\n",
        "\n",
        ">In our case, pandas.Series.str.replace() is needed.\n",
        "\n"
      ],
      "metadata": {
        "id": "-11lSvXMkrZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Hardware_Vendor'] = dataset['Hardware_Vendor'].str.replace(\"-\", \" \")"
      ],
      "metadata": {
        "id": "GQZ8B82lVFK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"tek\")\n",
        "dataset['Hardware_Vendor'] = dataset['Hardware_Vendor'].replace(\"giga byte\", \"gigabyte\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"cloud\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"incorporated\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"inc.\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"technologies\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"sas\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"performance\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"systems\")\n",
        "dataset['Hardware_Vendor'] = remove_after_with_delimiter(dataset['Hardware_Vendor'], \"microsystems\")"
      ],
      "metadata": {
        "id": "9sARQwdcU0Mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a result, the number of vendors downs to 47. Duplicates and unnecessary parts were eliminated."
      ],
      "metadata": {
        "id": "WKw6EqC9wxPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vendors = set(list(dataset['Hardware_Vendor']))\n",
        "print(len(vendors))\n",
        "print(sorted(vendors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryl3sqswkMvN",
        "outputId": "70f06eac-28d1-4e25-f241-d0859f83b1e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47\n",
            "['acer', 'action', 'apple', 'asus', 'boxx', 'bull', 'cisco', 'clearcube', 'clevo', 'cryo', 'dell', 'e4', 'format', 'fujitsu', 'fujitsu siemens', 'gigabyte', 'h3c', 'hewlett packard', 'hitachi', 'huawei', 'hyper', 'ibm', 'incom', 'inspur', 'intel', 'itautec', 'iwill', 'lenovo', 'm', 'maxdata ag', 'microsoft', 'msi', 'nec', 'nokia', 'ntt system', 'oracle', 'pc factory', 'quanta', 'sgi', 'sugon', 'sun micro', 'supermicro', 'tyan', 'unisys', 'wipro', 'yoyotech', 'zte']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two exceptions:\n",
        "\n",
        "\n",
        "1.   M Computers' name must be still as it is.\n",
        "2.   Sun Microsystems is also known as Sun. For further processes, we decided use it."
      ],
      "metadata": {
        "id": "3PDMQdAKjgeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "hw_vendors = list(dataset['Hardware_Vendor'])\n",
        "while i < len(dataset['Hardware_Vendor']):\n",
        "  if hw_vendors[i] == \"m\":\n",
        "    hw_vendors[i] = \"m computers\"\n",
        "  elif hw_vendors[i] == \"sun micro\":\n",
        "    hw_vendors[i] = \"sun\"\n",
        "  i += 1\n",
        "dataset['Hardware_Vendor'] = hw_vendors"
      ],
      "metadata": {
        "id": "9IRdd1wxjtg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CORES, CHIPS, THREADS, and ORDERABLE CPU(s)**"
      ],
      "metadata": {
        "id": "5YIs9wUZwHtW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SPEC2006 dataset contains 5 attributes that related each other: \"# Cores\", \"# Chips\", \"# Cores Per Chip\", \"# Threads Per Core\", and \"CPU(s) Orderable\". These involve similar info, so we eliminate some of them. Besides, in these columns, there are some inconsistencies in their values. For example, the system named \"Bull Escala PL1650R+ (2200 MHz, 1 CPU)\" has 1 chip and 2 cores per chip, but the total number of cores was entered 1. Therefore, we have to check and correct each value of the number of cores."
      ],
      "metadata": {
        "id": "K7JMk-erEzP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function below multiplies the number of chips per core and the number of cores to find the total number of cores."
      ],
      "metadata": {
        "id": "ngD8b9nZMtby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_core_nums(chips, cores_per_chips):\n",
        "  chips = list(chips)\n",
        "  cores_per_chips = list(cores_per_chips)\n",
        "  cores = []\n",
        "  i = 0\n",
        "  while i < len(chips):\n",
        "    cores.append(cores_per_chips[i] * chips[i])\n",
        "    i += 1\n",
        "  return cores"
      ],
      "metadata": {
        "id": "hPKDrg0OrsOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We do not need the information of the number of cores per chip anymore after calculating the total number of cores. Likewise, the number of orderable CPUs is irrelevant. For this reason, we eliminate that column after copying it to a list."
      ],
      "metadata": {
        "id": "HX6oWXWJM3eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.drop(['CPU(s)_Orderable'], axis = 1)\n",
        "cores_per_chips = dataset['#_Cores_Per_Chip']\n",
        "dataset = dataset.drop(['#_Cores_Per_Chip'], axis = 1)"
      ],
      "metadata": {
        "id": "v1x8K1s2jdY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, we update the values of the number of cores."
      ],
      "metadata": {
        "id": "MxBAdaB_NzBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['#_Cores'] = correct_core_nums(dataset['#_Chips'], cores_per_chips)"
      ],
      "metadata": {
        "id": "o4efNR3GNwyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Besides the total number of cores, the total number of threads are required. The function below calculates it."
      ],
      "metadata": {
        "id": "fAc5LAB5Ptot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_thread_nums(cores, threads_per_chips):\n",
        "  cores = list(cores)\n",
        "  threads_per_chips = list(threads_per_chips)\n",
        "  threads = []\n",
        "  i = 0\n",
        "  while i < len(cores):\n",
        "    threads.append(threads_per_chips[i] * cores[i])\n",
        "    i += 1\n",
        "  return threads"
      ],
      "metadata": {
        "id": "Ay30a0X8itet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We eliminate the number of threads per core and add a new column named #_Threads. Below, we update the values of the total number of threads."
      ],
      "metadata": {
        "id": "xPtFWh17Q4CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threads_per_chips = dataset['#_Threads_Per_Core']\n",
        "dataset = dataset.drop(['#_Threads_Per_Core'], axis = 1)\n",
        "threads = calculate_thread_nums(dataset['#_Cores'], threads_per_chips)\n",
        "dataset.insert(8, \"#_Threads\", threads, True)"
      ],
      "metadata": {
        "id": "8YAFYs3a7gYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, as the information of the number of chips is contained in the \"#_Chips\" column, we drop the \"CPU(s) Orderable\" column. "
      ],
      "metadata": {
        "id": "hJcq_yPvsZR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(['CPU(s)_Orderable'], axis = 1)"
      ],
      "metadata": {
        "id": "EPUIUyVAtFQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CACHES**"
      ],
      "metadata": {
        "id": "tsVSYI_suNCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the dataset, there are 4 types of caches: 1st Level, 2nd Level, 3rd Level, and Other. The codes below turn them into their numerical values."
      ],
      "metadata": {
        "id": "nMbrBb0Iu8BF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method Name:** calculate_cache_size\n",
        "\n",
        "**Parameters:** pd.DataFrame, Column_Names\n",
        "\n",
        "**Return:** pd.DataFrame.columns\n",
        "\n",
        "The main goal is to find the total size of each cache. Caches can be for either instructions or data, however, this is irrelevant for our further studies.\n",
        "This function split the data of the cells of the columns related to caches. It is designed for 1st, 2nd, and 3rd caches particularly. As seen in the further parts of the main script, the data in the cells are updated. As a result, relatively more clear data can be sent to this function as the parameter. Before dropping unnecessary parts, the data was like:\n",
        "\n",
        "> 16 MB I+D on chip per chip, 2 MB shared / 2 cores\n",
        "\n",
        "After cleaning:\n",
        "\n",
        "> 16 MB I+D on chip per chip\n",
        "\n",
        "Then, this function calculates the total size of the cache as\n",
        "\n",
        "> 16 x 1000 x num_of_chips\n",
        "\n",
        "Here, we accept that 1MB equals 1000 KB to ease convertions."
      ],
      "metadata": {
        "id": "zRJAO_abw8-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_cache_size(dataset: pd.DataFrame, column_name: Column_Names) -> pd.DataFrame.columns:\n",
        "  caches = list(dataset[column_name.value])\n",
        "  chips = list(dataset['#_Chips'])\n",
        "  cores = list(dataset['#_Cores'])\n",
        "  i = 0\n",
        "  while i < len(caches):\n",
        "    if caches[i] == \"none\":\n",
        "      caches[i] = 0\n",
        "    else:\n",
        "      cache = 0\n",
        "      parts = caches[i].split(\"+\")\n",
        "      if len(parts) == 1:\n",
        "        num = eliminate_non_digits(parts[0])\n",
        "        if \"mb\" in parts[0]:\n",
        "          num = num * 1000\n",
        "        if \"per chip\" in parts[0]:\n",
        "          cache = num * chips[i]\n",
        "        elif \"per core\" in parts[0]:\n",
        "          cache = num * cores[i]\n",
        "        caches[i] = cache\n",
        "      elif len(parts) == 2:\n",
        "        num1 = eliminate_non_digits(parts[0])\n",
        "        if \"mb\" in parts[0]:\n",
        "          num1 = num1 * 1000\n",
        "        num2 = eliminate_non_digits(parts[1])\n",
        "        if \"mb\" in parts[1]:\n",
        "          num2 = num2 * 1000\n",
        "        if num2 == 0:\n",
        "          if \"per core\" in parts[1]:\n",
        "            cache = num1 * cores[i]\n",
        "          elif \"per chip\" in parts[1]:\n",
        "            cache = num1 * chips[i]\n",
        "          caches[i] = cache\n",
        "        else:\n",
        "          if parts[0].find(\"per core\") == -1 and parts[0].find(\"per chip\") == -1:\n",
        "            cache = num1 + num2\n",
        "            if \"per core\" in parts[1]:\n",
        "              cache = cache * cores[i]\n",
        "            elif \"per chip\" in parts[1]:\n",
        "              cache = cache * chips[i]\n",
        "            caches[i] = cache\n",
        "          else:\n",
        "            if \"per core\" in parts[0]:\n",
        "              cache = num1 * cores[i]\n",
        "            elif \"per chip\" in parts[0]:\n",
        "              cache = num1 * chips[i]            \n",
        "            if \"per core\" in parts[1]:\n",
        "              cache += num2 * cores[i]\n",
        "            elif \"per chip\" in parts[0]:\n",
        "              cache += num2 * chips[i]\n",
        "            caches[i] = cache\n",
        "    i += 1\n",
        "  return caches"
      ],
      "metadata": {
        "id": "10LO8-BUReX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1st Level Cache**\n",
        "\n",
        "There are 22 different types of 1st level caches. Like Hardware_Vendor, there were 24 different types of 1st level caches before the \"row cleaning\" process. "
      ],
      "metadata": {
        "id": "VqwEw8aIvXfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['1st_Level_Cache'] = dataset['1st_Level_Cache'].str.lower()\n",
        "dataset['1st_Level_Cache'] = dataset['1st_Level_Cache'].str.strip()"
      ],
      "metadata": {
        "id": "56sMABe3Qx7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_level_caches = set(list(dataset['1st_Level_Cache']))\n",
        "print(len(first_level_caches))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWj0h4JMu7pR",
        "outputId": "e6963c6f-2bcf-4e0a-c6aa-60bd65f8ce1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_level_caches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxUUAYYAuMvc",
        "outputId": "027e38ca-0239-420f-b09c-9f394c12cb8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'12 k micro-ops i + 16 kb d on chip per chip',\n",
              " '12 k micro-ops i + 16 kb d on chip per core',\n",
              " '128 kb i + 128 kb d on chip per core',\n",
              " '128 kb i on chip per chip, 64 kb i shared / 2 cores; 16 kb d on chip per core',\n",
              " '128 kb i on chip per chip, 64 kb shared / 2 cores; 16 kb d on chip per core',\n",
              " '16 kb i + 16 kb d on chip per core',\n",
              " '16 kb i + 8 kb d on chip per core',\n",
              " '192 kb i on chip per chip, 64 kb i shared / 2 cores; 16 kb d on chip per core',\n",
              " '192 kb i on chip per chip, 96 kb i shared / 2 cores; 16 kb d on chip per core',\n",
              " '256 kb i on chip per chip, 64 kb i shared / 2 cores; 16 kb d on chip per core',\n",
              " '256 kb i on chip per chip, 64 kb shared / 2 cores; 16 kb d on chip per core',\n",
              " '32 kb i + 24 kb d on chip per core',\n",
              " '32 kb i + 32 kb d on chip per chip',\n",
              " '32 kb i + 32 kb d on chip per core',\n",
              " '32 kb i + 64 kb d on chip per core',\n",
              " '384 kb i on chip per chip, 64 kb i shared / 2 cores; 16 kb d on chip per core',\n",
              " '512 kb i on chip per chip, 64 kb i shared / 2 cores; 16 kb d on chip per core',\n",
              " '64 kb i + 32 kb d on chip per core',\n",
              " '64 kb i + 64 kb d on chip per chip',\n",
              " '64 kb i + 64 kb d on chip per core',\n",
              " '64 kb i on chip per chip; 16 kb d on chip per core',\n",
              " '96 kb i on chip per chip; 16 kb d on chip per core'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['1st_Level_Cache'] = remove_after_with_delimiter(dataset['1st_Level_Cache'], \"/\")\n",
        "dataset['1st_Level_Cache'] = remove_after_with_delimiter(dataset['1st_Level_Cache'], \",\")\n",
        "dataset['1st_Level_Cache'] = dataset['1st_Level_Cache'].str.replace(\";\", \" +\")\n",
        "dataset['1st_Level_Cache'] = dataset['1st_Level_Cache'].str.replace(\"12 k micro-ops i \\+ \", \"\")"
      ],
      "metadata": {
        "id": "FuywD51FRdtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['1st_Level_Cache'] = calculate_cache_size(dataset, Column_Names.first_cache)"
      ],
      "metadata": {
        "id": "sq-1MwLUReUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2nd Level Cache**\n",
        "\n",
        "There are 33 different types of 2nd level caches. Like Hardware_Vendor, there were 41 different types of 2nd level caches before the row cleaning process."
      ],
      "metadata": {
        "id": "DTneu-hmCnAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['2nd_Level_Cache'] = dataset['2nd_Level_Cache'].str.lower()\n",
        "dataset['2nd_Level_Cache'] = dataset['2nd_Level_Cache'].str.strip()"
      ],
      "metadata": {
        "id": "ScOMSduXeNQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_level_caches = set(list(dataset['2nd_Level_Cache']))\n",
        "print(len(second_level_caches))"
      ],
      "metadata": {
        "id": "BxnuJ2AruMkg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f39dbf84-e05c-42e6-a319-4e3964d4fd33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As known, sizes of 2nd level caches are bigger than 1st level caches. 2nd level caches generally are measured with MBs while 1st level caches are using KBs. "
      ],
      "metadata": {
        "id": "hiQ9TVw8Htk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "second_level_caches"
      ],
      "metadata": {
        "id": "-KkVldpguMiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a8b100-0c3e-4100-a708-2de0a0c9f893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1 mb i + 256 kb d on chip per core',\n",
              " '1 mb i+d on chip per chip',\n",
              " '1 mb i+d on chip per core',\n",
              " '1 mb i+d on chip per two cores',\n",
              " '11 mb i+d on chip per chip',\n",
              " '12 mb i+d on chip per chip',\n",
              " '12 mb i+d on chip per chip, 2 mb shared / 2 cores',\n",
              " '12 mb i+d on chip per chip, 6 mb shared / 2 cores',\n",
              " '128 kb i+d on chip per core',\n",
              " '16 mb i+d on chip per chip, 2 mb shared / 2 cores',\n",
              " '1920 kb i+d on chip per chip',\n",
              " '2 mb i on chip per chip (256 kb / 4 cores); 4 mb d on chip per chip (256 kb / 2 cores)',\n",
              " '2 mb i+d on chip per chip',\n",
              " '2 mb i+d on chip per core',\n",
              " '22 mb i+d on chip per chip',\n",
              " '24 mb i+d on chip per chip',\n",
              " '256 kb i+d on chip per core',\n",
              " '3 mb i+d on chip per chip',\n",
              " '4 mb i+d on chip per chip',\n",
              " '4 mb i+d on chip per chip, 1 mb i+d shared / 2 cores',\n",
              " '4 mb i+d on chip per chip, 2 mb shared / 2 cores',\n",
              " '4 mb i+d on chip per core',\n",
              " '5 mb i+d on chip per chip',\n",
              " '512 kb i + 256 kb d on chip per core',\n",
              " '512 kb i+d on chip per chip',\n",
              " '512 kb i+d on chip per core',\n",
              " '5632 kb i+d on chip per chip',\n",
              " '6 mb i+d on chip per chip',\n",
              " '6 mb i+d on chip per chip, 2 mb shared / 2 cores',\n",
              " '6 mb i+d on chip per chip, 3 mb shared / 2 cores',\n",
              " '8 mb i+d on chip per chip, 2 mb shared / 2 cores',\n",
              " '8 mb i+d on chip per chip, 4 mb shared / 2 cores',\n",
              " '9 mb i+d on chip per chip, 3 mb shared / 2 cores'}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['2nd_Level_Cache'] = remove_after_with_delimiter(dataset['2nd_Level_Cache'], \",\")\n",
        "dataset['2nd_Level_Cache'] = remove_after_with_delimiter(dataset['2nd_Level_Cache'], \"(\")"
      ],
      "metadata": {
        "id": "cOza_2OKeHsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['2nd_Level_Cache'] = calculate_cache_size(dataset, Column_Names.second_cache)"
      ],
      "metadata": {
        "id": "0UgJYVo7eHjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3rd Level Cache**\n",
        "\n",
        "There are 56 different types of 3rd level caches. Like Hardware_Vendor, there were 57 different types of 3rd level caches before the row cleaning process."
      ],
      "metadata": {
        "id": "37CwhD7tIsC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['3rd_Level_Cache'] = dataset['3rd_Level_Cache'].str.lower()\n",
        "dataset['3rd_Level_Cache'] = dataset['3rd_Level_Cache'].str.strip()"
      ],
      "metadata": {
        "id": "g-p4o5OIiwUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "third_level_caches = set(list(dataset['3rd_Level_Cache']))\n",
        "print(len(third_level_caches))"
      ],
      "metadata": {
        "id": "j8M4z9rGIsC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1459f676-d4d4-44ad-c15a-b008c2805826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "third_level_caches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2B1A78gIo-K",
        "outputId": "44fafdc0-0e34-4b31-b6fb-ba82b3021eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'10 mb i+d on chip per chip',\n",
              " '10 mb i+d on chip per core',\n",
              " '11 mb i+d on chip per chip',\n",
              " '12 mb i+d on chip per chip',\n",
              " '12 mb i+d on chip per chip, 6 mb shared / 4 cores',\n",
              " '12 mb i+d on chip per chip, 6 mb shared / 6 cores',\n",
              " '12 mb i+d on chip per core',\n",
              " '13.75 mb i+d on chip per chip',\n",
              " '15 mb i+d on chip per chip',\n",
              " '16 mb i+d on chip per chip',\n",
              " '16 mb i+d on chip per chip, 8 mb shared / 2 cores',\n",
              " '16 mb i+d on chip per chip, 8 mb shared / 4 cores',\n",
              " '16 mb i+d on chip per chip, 8 mb shared / 6 cores',\n",
              " '16 mb i+d on chip per chip, 8 mb shared / 8 cores',\n",
              " '16.5 mb i+d on chip per chip',\n",
              " '18 mb i+d on chip per chip',\n",
              " '19.25 mb i+d on chip per chip',\n",
              " '2 mb i+d on chip per chip',\n",
              " '20 mb i+d on chip per chip',\n",
              " '22 mb i+d on chip per chip',\n",
              " '24 mb i+d on chip per chip',\n",
              " '24.75 mb i+d on chip per chip',\n",
              " '25 mb i+d on chip per chip',\n",
              " '27.5 mb i+d on chip per chip',\n",
              " '3 mb i+d on chip per chip',\n",
              " '30 mb i+d on chip per chip',\n",
              " '30.25 mb i+d on chip per chip',\n",
              " '32 mb i+d off chip per chip',\n",
              " '32 mb i+d on chip per chip',\n",
              " '33 mb i+d on chip per chip',\n",
              " '35 mb i+d on chip per chip',\n",
              " '35.75 mb i+d on chip per chip',\n",
              " '36 mb i+d off chip per chip',\n",
              " '37.5 mb i+d on chip per chip',\n",
              " '38.5 mb i+d on chip per chip',\n",
              " '38400 kb i+d on chip per chip',\n",
              " '4 mb i+d on chip per chip',\n",
              " '4 mb i+d on chip per core',\n",
              " '40 mb i+d on chip per chip',\n",
              " '45 mb i+d on chip per chip',\n",
              " '5 mb i+d on chip per chip',\n",
              " '50 mb i+d on chip per chip',\n",
              " '55 mb i+d on chip per chip',\n",
              " '6 mb i+d on chip per chip',\n",
              " '6 mb i+d on chip per core',\n",
              " '60 mb i+d on chip per chip',\n",
              " '64 mb i+d on chip per chip (8 mb / 4 cores)',\n",
              " '64 mb i+d on chip per chip, 8 mb shared / 2 cores',\n",
              " '64 mb i+d on chip per chip, 8 mb shared / 3 cores',\n",
              " '64 mb i+d on chip per chip, 8 mb shared / 4 cores',\n",
              " '8 mb i+d on chip per chip',\n",
              " '8 mb i+d on chip per core',\n",
              " '8.25 mb i+d on chip per chip',\n",
              " '9 mb i+d on chip per chip',\n",
              " '9 mb i+d on chip per core',\n",
              " 'none'}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['3rd_Level_Cache'] = remove_after_with_delimiter(dataset['3rd_Level_Cache'], \",\")\n",
        "dataset['3rd_Level_Cache'] = remove_after_with_delimiter(dataset['3rd_Level_Cache'], \"(\")"
      ],
      "metadata": {
        "id": "nu-VyGfyi0O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['3rd_Level_Cache'] = calculate_cache_size(dataset, Column_Names.third_cache)"
      ],
      "metadata": {
        "id": "PBb51BELi0K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Other Caches**"
      ],
      "metadata": {
        "id": "esPcjPIfxfkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As there are 4 different types of other caches, we do not need to use a complex method."
      ],
      "metadata": {
        "id": "V4w5WIie0Szf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "other_caches = set(list(dataset['Other_Cache']))\n",
        "print(len(other_caches))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Udze_5hYxfks",
        "outputId": "bfb85227-8be2-453a-8d24-b03b4db7c5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "other_caches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxQXAWr2xfks",
        "outputId": "0eb52ad1-05b9-4d15-c575-f9e6d327b9cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'16 MB I+D off chip per 4 DIMMs',\n",
              " '16 MB I+D off chip per CDIMM',\n",
              " '16 MB I+D on chip per chip',\n",
              " 'None'}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_other_caches(dataset):\n",
        "  cache_column = list(dataset['Other_Cache'])\n",
        "  chip_column = list(dataset['#_Chips'])\n",
        "  i = 0\n",
        "  while i < len(cache_column):\n",
        "    stripped = str(cache_column[i]).strip()\n",
        "    if stripped == \"None\":\n",
        "      cache_column[i] = 0\n",
        "    else:\n",
        "      cache_column[i] = 16000 * chip_column[i]\n",
        "    i += 1\n",
        "  return cache_column"
      ],
      "metadata": {
        "id": "BCzo_hO6Io2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Other_Cache'] = handle_other_caches(dataset)"
      ],
      "metadata": {
        "id": "_wxYCP_NIozX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SYSTEM**"
      ],
      "metadata": {
        "id": "Nkyc8bT7gFBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In many cases, system names involve both the vendor's name and the processor specs. We have to get rid of them because that information has its own columns."
      ],
      "metadata": {
        "id": "8k_Fk6viD5ex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method Name:** remove_vendor_names\n",
        "\n",
        "**Parameters:** pd.DataFrame.columns, pd.DataFrame.columns\n",
        "\n",
        "**Return:** pd.DataFrame.columns\n",
        "\n",
        "This function deletes vendor names in system names."
      ],
      "metadata": {
        "id": "OWYwyzKrEy4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_vendor_names(systems: pd.DataFrame.columns, vendors: pd.DataFrame.columns) -> pd.DataFrame.columns:\n",
        "  vendors = list(set(list(vendors)))\n",
        "  systems = list(systems)\n",
        "  i = 0\n",
        "  while i < len(systems):\n",
        "    j = 0\n",
        "    temp = systems[i].strip()\n",
        "    while j < len(vendors):\n",
        "      if vendors[j] in temp:\n",
        "        start_index = systems[i].find(vendors[j])\n",
        "        end_index = start_index + len(vendors[j])\n",
        "        temp = temp[0:start_index:] + temp[end_index::]\n",
        "        systems[i] = temp.strip()\n",
        "        break\n",
        "      j +=1\n",
        "    i += 1\n",
        "  return systems"
      ],
      "metadata": {
        "id": "RF84_ShUBtVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['System'] = dataset['System'].str.lower()\n",
        "dataset['System'] = dataset['System'].str.strip()"
      ],
      "metadata": {
        "id": "ZhATASQYqOHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['System'] = remove_after_with_delimiter(dataset['System'], \"(\")\n",
        "dataset['System'] = remove_after_with_delimiter(dataset['System'], \",\")\n",
        "dataset['System'] = remove_after_with_delimiter(dataset['System'], \"amd\")\n",
        "dataset['System'] = dataset['System'].str.replace(\"motherboard\", \"\")\n",
        "dataset['System'] = dataset['System'].str.replace(\"-\", \" \")\n",
        "dataset['System'] = dataset['System'].str.replace(\"processor\", \"\")"
      ],
      "metadata": {
        "id": "WTeRF1Nqspld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['System'] = remove_vendor_names(dataset['System'], dataset['Hardware_Vendor'])"
      ],
      "metadata": {
        "id": "CXdb4uLaUrLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['System'] = dataset['System'].str.replace(\"2.60 ghz\\)\", \"\")"
      ],
      "metadata": {
        "id": "A2DnSK6Gjt4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['System'] = dataset['System'].str.strip()"
      ],
      "metadata": {
        "id": "KKyQFlV2uApK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = drop_empties(dataset, Column_Names.system, \"\")"
      ],
      "metadata": {
        "id": "t01cked0aqSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before eliminating duplicates, in the dataset, there are 1712 different system names."
      ],
      "metadata": {
        "id": "yTnqS65RMPf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "systems = set(list(dataset['System']))\n",
        "print(len(systems))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Efm_JSYb9iN",
        "outputId": "3537af09-b9df-456d-cc8c-a999b6018f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After eliminating redundancy from the dataset, we have to manage typos. In some cases, some system names were entered with different ways such as \"yr190b8228\" and \"yr190 b8228\".\n",
        "\n",
        "To solve this problem, we designed a method that finds anagrams as mentioned earlier. However, this cannot help us totally. Because there are real anagrams in the dataset such as \"poweredge r230\" and \"poweredge r320\". \n",
        "\n",
        "On the other hand, with the help of anagrams, we narrowed the search space down. The anagram finder finds 47 anagrams."
      ],
      "metadata": {
        "id": "UqF4Z-SKAuer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_systems, system_anagrams = find_anagrams(dataset['System'])\n",
        "print(len(system_anagrams))"
      ],
      "metadata": {
        "id": "pe3pgbkHdXWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61692b49-72b6-4123-d2f5-f0712c903a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we eliminate duplicated and typoed entries manually selecting from the list below."
      ],
      "metadata": {
        "id": "w0p_1DCEC2UE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "while i < len(system_anagrams):\n",
        "  print(original_systems[i] + \" - \" + system_anagrams[i])\n",
        "  i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_Fn0T6dj_ds",
        "outputId": "1c2fa787-9f5a-46fd-a611-a303e4663101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thinkserver rd120 - thinkserver rd210\n",
            "i610 g20 - i620 g10\n",
            "fire x4200m2 - fire x4200 m2\n",
            "primergy tx1310 m3 - primergy tx1330 m1\n",
            "yr190b8228 - yr190 b8228\n",
            "altos r380 f4 - altos r480 f3\n",
            "ucs c240m5 - ucs c240 m5\n",
            "proliant dl785 g5 - proliant dl585 g7\n",
            "blade sba 7142g t4 - blade sba7142g t4\n",
            "fire x6440 - fire x4640\n",
            "actina solar 402 a2 - actina solar 420 a2\n",
            "primergy rx600 s3 - primergy rx300 s6\n",
            "ucs b200m4 - ucs b200 m4\n",
            "ucs b420 m4 - ucs b440 m2\n",
            "actina solar 202 s5 - actina solar 220 s5\n",
            "tecal rh5885 v2 - tecal  rh5885 v2\n",
            "express5800/r110i 1 - express5800/110ri 1\n",
            "primergy rx2530m4 - primergy rx2530 m4\n",
            "aw2000 aw370h f3 - aw2000h f3 aw370\n",
            "express5800/r110h 1 - express5800/110rh 1\n",
            "poweredge r230 - poweredge r320\n",
            "system x3400 m3 - system x3300 m4\n",
            "express5800/gt110e - express5800/t110g e\n",
            "system x3690 x5 - system x3950 x6\n",
            "ucs c420 m3 - ucs c240 m3\n",
            "actina solar 202 x2 - actina solar 220 x2\n",
            "thinkserver rd540 - thinkserver rd450\n",
            "primergy tx300 s6 - primergy tx600 s3\n",
            "thinksystem sr590 - thinksystem sr950\n",
            "system x3650 m2 - system x3250 m6\n",
            "system x3650 m5 - system x3550 m6\n",
            "superserver 1028gr tr - superserver1028gr tr\n",
            "bladecenter hs12 - bladecenter hs21\n",
            "actina solar 210 s5 - actina solar 120 s5\n",
            "proliant dl360 g7 - proliant dl370 g6\n",
            "actina solar 202 s6 - actina solar 220 s6\n",
            "poweredge t130 - poweredge t310\n",
            "a+ server 2024g 6rf - a+ server 2042g 6rf\n",
            "poweredge fc640 - poweredgefc640\n",
            "primergy tx1320 m3 - primergy tx1330 m2\n",
            "proliant dl580 gen9 - proliant dl580 gen 9\n",
            "novascale r480e1 - novascale r480 e1\n",
            "system x3550 m2 - system x3250 m5\n",
            "altos r360 f4 - altos r460 f3\n",
            "superserver 6027r wrf - superserver 6072r wrf\n",
            "ar 780 f3 - ar780 f3\n",
            "power 575 - power 755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a result, we corrected 15 different system entries manually as below."
      ],
      "metadata": {
        "id": "BzJpdWzkGsnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['System'] = dataset['System'].replace(\"yr190b8228\", \"yr190 b8228\")\n",
        "dataset['System'] = dataset['System'].replace(\"novascale r480e1\", \"novascale r480 e1\")\n",
        "dataset['System'] = dataset['System'].replace(\"tecal  rh5885 v2\", \"tecal rh5885 v2\")\n",
        "dataset['System'] = dataset['System'].replace(\"ucs c240m5\", \"ucs c240 m5\")\n",
        "dataset['System'] = dataset['System'].replace(\"fire x4200m2\", \"fire x4200 m2\")\n",
        "dataset['System'] = dataset['System'].replace(\"ucs b200m4\", \"ucs b200 m4\")\n",
        "dataset['System'] = dataset['System'].replace(\"blade sba7142g t4\", \"blade sba 7142g t4\")\n",
        "dataset['System'] = dataset['System'].replace(\"poweredgefc640\", \"poweredge fc640\")\n",
        "dataset['System'] = dataset['System'].replace(\"primergy rx2530m4\", \"primergy rx2530 m4\")\n",
        "dataset['System'] = dataset['System'].replace(\"superserver1028gr tr\", \"superserver 1028gr tr\")\n",
        "dataset['System'] = dataset['System'].replace(\"ar 780 f3\", \"ar780 f3\")\n",
        "dataset['System'] = dataset['System'].replace(\"proliant dl580 gen 9\", \"proliant dl580 gen9\")"
      ],
      "metadata": {
        "id": "50O5_hDlCjmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PROCESSORS**"
      ],
      "metadata": {
        "id": "Q0sEyRvCT3qf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 1022 different processors in the dataset. However, like the System column, it is required to check whether there are duplicated processor names because of typos."
      ],
      "metadata": {
        "id": "qNkN84aCUIYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Processor'] = dataset['Processor'].str.lower()\n",
        "dataset['Processor'] = dataset['Processor'].str.strip()"
      ],
      "metadata": {
        "id": "eohJShbqwJM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Processor'] = dataset['Processor'].str.replace(\"intel\", \"\")\n",
        "dataset['Processor'] = dataset['Processor'].str.replace(\"amd\", \"\")"
      ],
      "metadata": {
        "id": "3RMi7gAiwjER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processors = set(list(dataset['Processor']))\n",
        "print(len(processors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7aACiUiUNln",
        "outputId": "c3aed5ef-ad29-45b1-8b1a-172d10863e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, clear \"-\"s from the data is required."
      ],
      "metadata": {
        "id": "ejJgkpU_OVmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Processor'] = dataset['Processor'].str.replace(\"-\", \"\")"
      ],
      "metadata": {
        "id": "MhDc0WpPOdYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_processors, processor_anagrams = find_anagrams(dataset['Processor'])\n",
        "print(len(processor_anagrams))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkV06QyTMsHB",
        "outputId": "1ee77cc1-7e9d-4c2f-92df-527bda4c1891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "while i < len(processor_anagrams):\n",
        "  print(original_processors[i] + \" - \" + processor_anagrams[i])\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "5c0cw6j6NHZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4272fd77-b094-4714-b930-d95f1c155ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " core 2 duo e7600 -  core 2 duo e6700\n",
            " xeon e51630 v4 -  xeon e54610 v3\n",
            " pentium dualcore e2160 -  pentium dual core e2160\n",
            " xeon x6550 -  xeon x5650\n",
            " xeon x6550 -  xeon x5560\n",
            " xeon e5640 -  xeon e6540\n",
            " opteron 8374 he -  opteron 8347 he\n",
            " opteron 2218 -  opteron 8212\n",
            " xeon e52658 v3 -  xeon e52685 v3\n",
            " xeon x7542 -  xeon x5472\n",
            " opteron 4122 -  opteron 2214\n",
            " xeon e52623 v4 -  xeon e52643 v2\n",
            " xeon e54620 -  xeon e52640\n",
            " xeon e52620 v3 -  xeon e52630 v2\n",
            " xeon e52620 v3 -  xeon e52603 v2\n",
            " xeon e7430 -  xeon e7340\n",
            " xeon e52603 v3 -  xeon e52630 v3\n",
            " xeon e52403 -  xeon e52430\n",
            " xeon e52403 v2 -  xeon e52430 v2\n",
            " xeon e74807 -  xeon e74870\n",
            " xeon e31220 v3 -  xeon e31230 v2\n",
            " xeon e54603 v2 -  xeon e54620 v3\n",
            " xeon e54603 v2 -  xeon e52630 v4\n",
            " xeon e54603 v2 -  xeon e52640 v3\n",
            " xeon e54603 v2 -  xeon e52603 v4\n",
            " xeon e74830 v2 -  xeon e74820 v3\n",
            " xeon e52603 -  xeon e52630\n",
            " opteron 8216 -  opteron 6128\n",
            " xeon e52690 v3 -  xeon e52609 v3\n",
            " opteron 8378 -  opteron 8387\n",
            " xeon e52650 v4 -  xeon e54650 v2\n",
            " xeon e51603 v3 -  xeon e51630 v3\n",
            " opteron 2435 -  opteron 2354\n",
            " opteron 2347 he -  opteron 2374 he\n",
            " xeon e7450 -  xeon e7540\n",
            " xeon e52648l v2 -  xeon e52628l v4\n",
            " opteron 6212 -  opteron 2216\n",
            " xeon e74890 v2 -  xeon e74809 v2\n",
            " core i75960x -  core i76950x\n",
            " xeon e52689 v4 -  xeon e52698 v4\n",
            " xeon e5502 -  xeon e5205\n",
            " xeon e5502 -  xeon e5520\n",
            " core i53340 -  core i34350\n",
            " xeon e5540 -  xeon e5450\n",
            " xeon e5540 -  xeon e5504\n",
            " xeon e5540 -  xeon e5405\n",
            " opteron 6238 -  opteron 6328\n",
            " xeon e52690 -  xeon e52609\n",
            " opteron 2378 -  opteron 2387\n",
            " xeon e52407 -  xeon e52470\n",
            " opteron 4238 -  opteron 2384\n",
            " xeon e52620 v4 -  xeon e54620 v2\n",
            " xeon e52620 v4 -  xeon e52640 v2\n",
            " xeon x3320 -  xeon x3230\n",
            " pentium g3240 -  pentium g3420\n",
            " xeon e5630 -  xeon e5603\n",
            " xeon e52609 v2 -  xeon e52690 v2\n",
            " xeon x5570 -  xeon x7550\n",
            " xeon e5503 -  xeon e5530\n",
            " xeon w3550 -  xeon w3505\n",
            " xeon l5240 -  xeon l5420\n",
            " xeon e72830 -  xeon e72803\n",
            " xeon e54610 v2 -  xeon e51620 v4\n",
            " xeon l7455 -  xeon l7545\n",
            " opteron 8354 -  opteron 8435\n",
            " pentium dualcore e2140 -  pentium dual core e2140\n",
            " xeon e52407 v2 -  xeon e52470 v2\n",
            " xeon e52690 v4 -  xeon e52609 v4\n",
            " xeon e54620 v4 -  xeon e54640 v2\n",
            " xeon e54620 v4 -  xeon e52640 v4\n",
            " opteron 3280 -  opteron 2380\n",
            " xeon e52648l v4 -  xeon e54628l v4\n",
            " xeon x7560 -  xeon x5670\n",
            " opteron 6348 -  opteron 4386\n",
            " opteron 6308 -  opteron 6380\n",
            " xeon e52637 v4 -  xeon e54627 v3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Processor'] = dataset['Processor'].str.replace(\"pentium dualcore e2160\", \"pentium dual core e2160\")\n",
        "dataset['Processor'] = dataset['Processor'].str.replace(\"pentium dualcore e2140\", \"pentium dual core e2140\")"
      ],
      "metadata": {
        "id": "2LBlaejuNHV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Processor_Characteristics column is not relevant for our further studies, thus we eliminate it either."
      ],
      "metadata": {
        "id": "Jp26M_TG_jEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(['Processor_Characteristics'], axis = 1)"
      ],
      "metadata": {
        "id": "yKSofHRBNHRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MEMORY**"
      ],
      "metadata": {
        "id": "kb6CvWATAmN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the dataset, the Memory column contains not only the size of the system memory but also the combination of memory components such as \"32 GB (4 x 8 GB 2Rx8 PC3-12800E-11, ECC)\". As we only need the total size of the memory, we eliminate the parts between brackelets and commas."
      ],
      "metadata": {
        "id": "xeEDLHbEAmN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Memory'] = dataset['Memory'].str.lower()\n",
        "dataset['Memory'] = dataset['Memory'].str.strip()"
      ],
      "metadata": {
        "id": "FfphsaCSAmN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Memory'] = remove_after_with_delimiter(dataset['Memory'], \"(\")\n",
        "dataset['Memory'] = remove_after_with_delimiter(dataset['Memory'], \",\")\n",
        "dataset['Memory'] = dataset['Memory'].str.strip()"
      ],
      "metadata": {
        "id": "_2u2ja-2BvDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memories = set(list(dataset['Memory']))\n",
        "print(len(memories))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uT9I5hDAsF_",
        "outputId": "e3fd0ca7-76fb-4253-e8a1-eef41f9dfbb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memories"
      ],
      "metadata": {
        "id": "AzOTs0zUAsDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e07a8cbd-db5d-4203-df04-531ac37cad43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1 gb',\n",
              " '1 tb',\n",
              " '112 gb',\n",
              " '1152 gb',\n",
              " '12 gb',\n",
              " '120 gb',\n",
              " '128 gb',\n",
              " '1536 gb',\n",
              " '16 gb',\n",
              " '16 tb',\n",
              " '160 gb',\n",
              " '192 gb',\n",
              " '2 gb',\n",
              " '2 tb',\n",
              " '208 gb',\n",
              " '24 gb',\n",
              " '240 gb',\n",
              " '256 gb',\n",
              " '284 gb',\n",
              " '3 tb',\n",
              " '304 gb',\n",
              " '32 gb',\n",
              " '36 gb',\n",
              " '384 gb',\n",
              " '4 gb',\n",
              " '4 tb',\n",
              " '400 gb',\n",
              " '48 gb',\n",
              " '500 gb',\n",
              " '512 gb',\n",
              " '6 gb',\n",
              " '64 gb',\n",
              " '640 gb',\n",
              " '704 gb',\n",
              " '72 gb',\n",
              " '768 gb',\n",
              " '8 gb',\n",
              " '8 tb',\n",
              " '8320 gb',\n",
              " '8576 gb',\n",
              " '9 gb',\n",
              " '96 gb',\n",
              " '976 gb'}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After eliminating non-essential parts, TB to GB conversions is applied. As cache sizes, we use thousand system: 1 TB = 1000 GB."
      ],
      "metadata": {
        "id": "QP4BWNrIV865"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_TB_to_GB(column: pd.DataFrame.columns) -> pd.DataFrame.columns:\n",
        "  column = list(column)\n",
        "  i = 0\n",
        "  while i < len(column):\n",
        "    if \"gb\" in column[i]:\n",
        "      column[i] = eliminate_non_digits(column[i])\n",
        "    else:\n",
        "      x = eliminate_non_digits(column[i])\n",
        "      column[i] = 1000 * eliminate_non_digits(column[i])\n",
        "    i += 1\n",
        "  return column"
      ],
      "metadata": {
        "id": "eN36zIdqAsAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Memory'] = convert_TB_to_GB(dataset['Memory'])"
      ],
      "metadata": {
        "id": "KbKY5SZkAr9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **FILE SYSTEM**"
      ],
      "metadata": {
        "id": "Vag1oXroe-tX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before applying following steps, there were 27 different types of file systems. After eliminating duplicates, we achieved to decrease it to 20."
      ],
      "metadata": {
        "id": "kQVVfQfve-tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['File_System'] = dataset['File_System'].str.lower()\n",
        "dataset['File_System'] = dataset['File_System'].str.strip()"
      ],
      "metadata": {
        "id": "JRRkXN-3fWd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_sys = set(list(dataset['File_System']))\n",
        "print(len(file_sys))"
      ],
      "metadata": {
        "id": "9EFI25yufWd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78bc0049-621a-45e8-80e6-be2a6e2f8964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_sys"
      ],
      "metadata": {
        "id": "KNBTgSuDXmie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92685ec5-c148-4f0c-bfb0-da4aa842dc32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(see additional details below)',\n",
              " 'aix/jfs2',\n",
              " 'benchmark on ufs, os on zfs',\n",
              " 'btfs',\n",
              " 'btrfs',\n",
              " 'ext2',\n",
              " 'ext3',\n",
              " 'ext4',\n",
              " 'hfs+',\n",
              " 'lustre v1.6.7 over ddr infiniband',\n",
              " 'nfsv3',\n",
              " 'nfsv3 (see additional details below)',\n",
              " 'nfsv3 ipoib',\n",
              " 'nfsv3, ipoib',\n",
              " 'nfsv4',\n",
              " 'ntfs',\n",
              " 'os on zfs, benchmark on ufs',\n",
              " 'reiserfs',\n",
              " 'tmpfs',\n",
              " 'tmpfs (output_root was used to put run directories in /tmp/cpu2006) zfs',\n",
              " 'ufs',\n",
              " 'vxfs',\n",
              " 'xfs',\n",
              " 'zfs',\n",
              " 'zfs (with raidz)',\n",
              " 'zfs and tmpfs',\n",
              " 'zfs with gzip compression'}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['File_System'] = remove_between_with_delimiter(dataset['File_System'], \"(\", \")\")"
      ],
      "metadata": {
        "id": "4mnpuuWJW2G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = drop_empties(dataset, Column_Names.file_system, \"\")"
      ],
      "metadata": {
        "id": "l92DO-jbEwvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['File_System'] = dataset['File_System'].str.replace(\",\", \"\")\n",
        "dataset['File_System'] = dataset['File_System'].str.replace(\"/\", \" \")\n",
        "dataset['File_System'] = remove_after_with_delimiter(dataset['File_System'], \"with\")\n",
        "dataset['File_System'] = remove_after_with_delimiter(dataset['File_System'], \"v1.\")\n",
        "dataset['File_System'] = dataset['File_System'].replace(\"tmpfs  zfs\", \"tmpfs zfs\")\n",
        "dataset['File_System'] = dataset['File_System'].replace(\"zfs and tmpfs\", \"tmpfs zfs\")\n",
        "dataset['File_System'] = dataset['File_System'].replace(\"os on zfs benchmark on ufs\", \"ufs zfs\")\n",
        "dataset['File_System'] = dataset['File_System'].replace(\"benchmark on ufs os on zfs\", \"ufs zfs\")\n",
        "dataset['File_System'] = dataset['File_System'].str.replace(\" \", \" + \")"
      ],
      "metadata": {
        "id": "6IT6cE1qEwrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EXPORTING THE DATASET**"
      ],
      "metadata": {
        "id": "Cq5nz88_df6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In our case, we export the modified dataset to our own Google Drive folder. Thus, in your study, you have to change the path where you export the dataset.**"
      ],
      "metadata": {
        "id": "8LYp1aKGnR0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.to_excel(r'/content/drive/MyDrive/Colab Notebooks/Datasets/SPEC/SPEC2006_modified.xlsx', index = False, header = True)"
      ],
      "metadata": {
        "id": "gUgpB4-WZ8wG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}